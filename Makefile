.PHONY: help setup init start schema load transform validate export powerbi-info backup stop clean logs refresh test all

# Variables de ConfiguraciÃ³n
PYTHON := python
VENV := .venv
PIP := $(VENV)/bin/pip
PYTHON_VENV := $(VENV)/bin/python
DOCKER_COMPOSE := docker-compose -f config/docker-compose.yml
DB_HOST := localhost
DB_PORT := 5433
DB_NAME := supply_chain_dw
DB_USER := admin
DB_PASS := adminpassword

# Colores para output
GREEN := \033[0;32m
YELLOW := \033[1;33m
BLUE := \033[0;34m
RED := \033[0;31m
NC := \033[0m

# ============================================================================
# COMANDOS PRINCIPALES
# ============================================================================

help: ## ğŸ“– Mostrar ayuda
	@echo "$(GREEN)â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•$(NC)"
	@echo "$(GREEN)  ğŸ¢ TORRE CONTROL - Supply Chain Analytics$(NC)"
	@echo "$(GREEN)â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•$(NC)"
	@echo ""
	@echo "  $(BLUE)setup$(NC)               ğŸ”§ Instalar dependencias Python"
	@echo "  $(BLUE)init$(NC)                ğŸ“ Crear estructura de carpetas"
	@echo "  $(BLUE)start$(NC)               ğŸ³ Iniciar PostgreSQL + PgAdmin"
	@echo "  $(BLUE)schema$(NC)              ğŸ“‹ Crear esquema DW"
	@echo "  $(BLUE)load$(NC)                ğŸ“¥ Cargar datos raw â†’ staging"
	@echo "  $(BLUE)transform$(NC)           âš™ï¸  Transformar staging â†’ Star Schema"
	@echo "  $(BLUE)validate$(NC)            âœ… Validar calidad de datos"
	@echo "  $(BLUE)export$(NC)              ğŸ“¤ Exportar CSV para Power BI"
	@echo "  $(BLUE)test$(NC)                ğŸ§ª Ejecutar tests unitarios"
	@echo "  $(BLUE)backup$(NC)              ğŸ’¾ Backup de PostgreSQL"
	@echo "  $(BLUE)stop$(NC)                ğŸ›‘ Detener contenedores"
	@echo "  $(BLUE)clean$(NC)               ğŸ§¹ Limpiar datos procesados"
	@echo "  $(BLUE)refresh$(NC)             ğŸ”„ Refresh completo (drop â†’ load â†’ transform)"
	@echo "  $(BLUE)all$(NC)                 ğŸš€ Pipeline completo"
	@echo ""
	@echo "$(YELLOW)ğŸ¯ Quick Start:$(NC) make all"
	@echo ""

setup: ## ğŸ”§ Instalar dependencias Python
	@echo "$(BLUE)ğŸ“¦ Instalando dependencias...$(NC)"
	pip install -r requirements.txt
	@echo "$(GREEN)âœ… Dependencias instaladas$(NC)"

init: ## ğŸ“ Crear estructura estÃ¡ndar (Cookiecutter Data Science)
	@echo "$(BLUE)ğŸ“ Creando carpetas...$(NC)"
	@mkdir -p data/raw data/interim data/processed data/external
	@mkdir -p notebooks tests logs models
	@touch data/.gitkeep notebooks/.gitkeep tests/__init__.py logs/.gitkeep
	@touch src/__init__.py src/etl/__init__.py
	@echo "$(GREEN)âœ… Estructura creada$(NC)"

start: ## ğŸ³ Iniciar PostgreSQL + PgAdmin (Docker)
	@echo "$(BLUE)ğŸ³ Iniciando contenedores...$(NC)"
	$(DOCKER_COMPOSE) up -d
	@echo "$(YELLOW)â³ Esperando PostgreSQL (10s)...$(NC)"
	@sleep 10
	@echo "$(GREEN)âœ… PostgreSQL listo en $(DB_PORT)$(NC)"
	@echo "$(GREEN)âœ… PgAdmin: http://localhost:5050$(NC)"

schema: start ## ğŸ“ Crear schema DW (DDL completo)
	@echo "$(BLUE)ğŸ“ Ejecutando DDL...$(NC)"
	@docker exec -i supply_chain_db psql -U $(DB_USER) -d $(DB_NAME) \
		< sql/ddl/01_schema_base.sql
	@echo "$(GREEN)âœ… Schema creado: dw.* tables$(NC)"

load: ## ğŸ“¥ Cargar CSV â†’ stg_raw_orders (PRODUCCIÃ“N)
	@echo "$(BLUE)ğŸ“¥ Ejecutando load_data.py...$(NC)"
	@if [ ! -f "Data/Raw/DataCoSupplyChainDataset.csv" ]; then \
		echo "$(RED)âŒ Dataset no encontrado en Data/Raw/$(NC)"; \
		exit 1; \
	fi
	$(PYTHON) scripts/load_data.py
	@echo "$(GREEN)âœ… Staging poblado$(NC)"

transform: ## ğŸ”„ Transformar â†’ Star Schema (USA SQL NATIVO)
	@echo "$(BLUE)ğŸ”„ Ejecutando transform_star_schema.py...$(NC)"
	$(PYTHON) scripts/transform_star_schema.py
	@echo "$(GREEN)âœ… Star Schema poblado:$(NC)"
	@echo "   - dim_customer (38K)"
	@echo "   - dim_geography (213)"
	@echo "   - dim_product (98)"
	@echo "   - dim_date (1,127)"
	@echo "   - fact_orders (150K)"

validate: ## âœ… Validar calidad de datos
	@echo "$(BLUE)ğŸ” Validando DW...$(NC)"
	@$(PYTHON) scripts/validate_dw.py

export: ## ğŸ“¤ Exportar CSV para Power BI (PostgreSQL â†’ CSV)
	@echo "$(BLUE)ğŸ“¤ Exportando a Data/Processed/...$(NC)"
	@mkdir -p Data/Processed
	@$(PYTHON) src/etl/export_star_schema.py
	@echo "$(GREEN)âœ… CSVs exportados:$(NC)"
	@ls -lh Data/Processed/*.csv 2>/dev/null || echo "   (ejecutar despuÃ©s de transform)"

powerbi-info: ## ğŸ“Š Info de conexiÃ³n Power BI
	@echo ""
	@echo "$(GREEN)â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•$(NC)"
	@echo "$(GREEN)  ğŸ“Š POWER BI - ConexiÃ³n DirectQuery$(NC)"
	@echo "$(GREEN)â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•$(NC)"
	@echo ""
	@echo "  Servidor:       $(DB_HOST):$(DB_PORT)"
	@echo "  Base de datos:  $(DB_NAME)"
	@echo "  Usuario:        $(DB_USER)"
	@echo "  ContraseÃ±a:     $(DB_PASS)"
	@echo "  Schema:         dw"
	@echo ""
	@echo "  Tablas:"
	@echo "    âœ“ dw.fact_orders"
	@echo "    âœ“ dw.dim_customer"
	@echo "    âœ“ dw.dim_geography"
	@echo "    âœ“ dw.dim_product"
	@echo "    âœ“ dw.dim_date"
	@echo ""

backup: ## ğŸ’¾ Crear backup PostgreSQL
	@echo "$(BLUE)ğŸ’¾ Creando backup...$(NC)"
	@mkdir -p backupsDocker
	$(DOCKER_COMPOSE) stop
	@echo "$(GREEN)âœ… Contenedores detenidos$(NC)"

clean: ## ğŸ§¹ Limpiar todo (âš ï¸ DATOS BORRADOS)
	@echo "$(RED)âš ï¸  Â¿Eliminar TODOS los datos? [y/N]:$(NC)" && read ans && [ $${ans:-N} = y ]
	$(DOCKER_COMPOSE) down -v
	rm -rf Data/Processed/*.csv logs/*.log
	@echo "$(GREEN)âœ… Limpieza completada$(NC)"

logs: ## ğŸ“‹ Ver logs PostgreSQL
	$(DOCKER_COMPOSE) logs -f postgres

test: ## ğŸ§ª Ejecutar tests unitarios (pytest)
	@echo "$(BLUE)ğŸ§ª Ejecutando tests...$(NC)"
	$(PYTHON) -m pytest tests/test_etl.py -v --tb=short

refresh: load transform validate ## ğŸ”„ Refresh ETL completo
	@echo "$(GREEN)âœ… ETL Refresh completado$(NC)"

all: setup init start schema load transform validate ## ğŸ¯ Pipeline completo
	@echo ""
	@echo "$(GREEN)â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•$(NC)"
	@echo "$(GREEN)  âœ… PIPELINE COMPLETADO$(NC)"
	@echo "$(GREEN)â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•$(NC)"
	@echo ""
	@echo "$(YELLOW)PrÃ³ximos pasos:$(NC)"
	@echo "  1. make export        â†’ Generar CSVs"
	@echo "  2. make powerbi-info  â†’ Ver conexiÃ³n"
	@echo "  3. make backup        â†’ Crear respaldo"
	@echo "  4. make test          â†’ Ejecutar tests"
	@echo ""

.DEFAULT_GOAL := help
create-transform: ## ğŸ”§ Crear script transform_data.py bÃ¡sico
	@echo "Creando scripts/transform_data.py..."
	@echo '#!/usr/bin/env python3' > scripts/transform_data.py
	@echo '"""Torre Control - ETL Transformation"""' >> scripts/transform_data.py
	@echo 'print("âš ï¸  Script de transformaciÃ³n pendiente de implementar")' >> scripts/transform_data.py
	@echo 'print("Ver documentaciÃ³n para crear populate_dim_* functions")' >> scripts/transform_data.py
	@chmod +x scripts/transform_data.py
	@echo "âœ… scripts/transform_data.py creado"