# Torre Control - ETL Pipeline Architecture

## ğŸ“‹ Production Pipeline

**Automated ETL workflow for Supply Chain Analytics**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ETL PIPELINE V2.0                        â”‚
â”‚              (SQL-based transformation)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Raw Data    â”‚  DataCoSupplyChainDataset.csv (180K records)
  â”‚  (CSV files) â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ python scripts/load_data.py
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Staging Layer   â”‚  dw.stg_raw_orders (50K records)
  â”‚  PostgreSQL DB   â”‚  - Raw data ingestion
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Basic data types
         â”‚
         â”‚ python scripts/transform_star_schema.py
         â”‚ (executes sql/populate_star_schema_simple.sql)
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚           Star Schema (Kimball)                â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  Dimensions:                                   â”‚
  â”‚    â€¢ dim_customer   (50K records)              â”‚
  â”‚    â€¢ dim_geography  (259 locations)            â”‚
  â”‚    â€¢ dim_product    (196 products)             â”‚
  â”‚    â€¢ dim_date       (1,127 dates)              â”‚
  â”‚                                                 â”‚
  â”‚  Facts:                                        â”‚
  â”‚    â€¢ fact_orders    (950K transactions)        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ Power BI Connector
                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚         Power BI Dashboard                     â”‚
  â”‚  - OTIF Performance                            â”‚
  â”‚  - Revenue at Risk                             â”‚
  â”‚  - VIP Churn Analysis                          â”‚
  â”‚  - Geographic Heatmap                          â”‚
  â”‚  - Anomaly Detection                           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. Load Raw Data to Staging
```bash
python scripts/load_data.py
```
**Output:** 50,000 records in `dw.stg_raw_orders`

### 2. Transform to Star Schema
```bash
python scripts/transform_star_schema.py
```
**Output:** 1M+ records across 5 tables (4 dimensions + 1 fact)

### 3. Connect Power BI
- **Host:** localhost:5433
- **Database:** supply_chain_dw
- **User:** admin
- **Schema:** dw

## ğŸ“ Script Reference

| Script | Purpose | Status |
|--------|---------|--------|
| `scripts/load_data.py` | CSV â†’ Staging | âœ… Production |
| `scripts/transform_star_schema.py` | Staging â†’ Star Schema | âœ… Production |
| `scripts/transform_data.py` | Pandas-based transform | âš ï¸  Deprecated |
| `sql/populate_star_schema_simple.sql` | SQL transformation | âœ… Production |

## ğŸ—ï¸ Architecture Decisions

### Why SQL for Transformations?

1. **Performance**: Native PostgreSQL processing > Pandas for large datasets
2. **Reliability**: Direct SQL = no schema mismatch issues
3. **Maintainability**: SQL transformations easier to review and modify
4. **Industry Standard**: Follows modern ELT pattern (dbt, Dataform, Fivetran)

### Pipeline Components

```python
# Load (Python orchestration)
scripts/load_data.py
  â”œâ”€ Reads CSV files
  â”œâ”€ Validates data types
  â””â”€ Bulk inserts to staging

# Transform (SQL execution via Python)
scripts/transform_star_schema.py
  â”œâ”€ Executes SQL script
  â”œâ”€ Verifies results
  â””â”€ Reports metrics

# SQL Transformation Logic
sql/populate_star_schema_simple.sql
  â”œâ”€ Dimension population (DISTINCT + dedup)
  â”œâ”€ Fact table population (JOINs)
  â””â”€ Data quality checks
```

## ğŸ“Š Data Lineage

```
DataCoSupplyChainDataset.csv
  â””â”€> stg_raw_orders (staging)
       â”œâ”€> dim_customer (Customer ID, Name, Segment)
       â”œâ”€> dim_geography (Market â†’ Region â†’ Country)
       â”œâ”€> dim_product (Product ID, Name, Category)
       â”œâ”€> dim_date (Date dimensions: Year, Month, Day)
       â””â”€> fact_orders (Foreign keys + Sales + OTIF metrics)
```

## ğŸ”§ Configuration

### Environment Variables (.env)
```bash
DATABASE_URL=postgresql://admin:adminpassword@localhost:5433/supply_chain_dw
PGPASSWORD=adminpassword
```

### Database Schema
- **Schema:** `dw` (data warehouse)
- **Tables:** 6 total (1 staging + 5 star schema)
- **Primary Keys:** Surrogate keys (auto-increment)
- **Foreign Keys:** Enforced referential integrity

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| **Staging Load** | ~10 seconds (50K records) |
| **Star Schema Transform** | ~56 seconds (1M records) |
| **Total Pipeline** | ~66 seconds end-to-end |
| **Data Growth Factor** | 20x (50K â†’ 1M records) |

## ğŸ› Troubleshooting

### Common Issues

**Issue:** `transform_data.py` schema errors  
**Solution:** Use `transform_star_schema.py` instead (SQL-based)

**Issue:** Duplicate records in dimensions  
**Solution:** SQL uses `DISTINCT` and conflict handling automatically

**Issue:** NULL foreign keys in facts  
**Solution:** Transform script filters out records with missing FKs

## ğŸ“š Documentation

- [ETL Complete Pipeline Guide](../docs/guides/ETL_COMPLETE_PIPELINE.md)
- [Transform Data Guide](../docs/guides/TRANSFORM_DATA_GUIDE.md)
- [Power BI Connection Guide](../docs/guides/POWER_BI_CONNECTION_COMPLETE_GUIDE.md)

## ğŸ¯ Next Phase: Analytics

After pipeline completion:
1. Build Power BI data model
2. Create DAX measures for 5 Strategic Questions
3. Design executive dashboards
4. Implement predictive analytics (Phase 3)

---

**Version:** 2.0  
**Last Updated:** 2026-02-04  
**Status:** Production Ready âœ…
