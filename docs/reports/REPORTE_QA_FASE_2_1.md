# ‚úÖ REPORTE QA - FASE 2.1: INGESTA CSV COMPLETADA

**Fecha:** 02 de Febrero de 2026  
**Hora:** ~20:15 UTC-5  
**Estado:** ‚úÖ **√âXITO - LISTO PARA FASE 2.2**

---

## üìä RESULTADOS DE CARGA

### M√©tricas Generales
```
Total de Filas Cargadas:           180,519
Columnas en Tabla:                 53
Archivo Fuente:                    data/raw/DataCoSupplyChainDataset.csv
Tama√±o Archivo:                    96 MB
Encoding:                          ISO-8859-1
M√©todo de Carga:                   Pandas + SQLAlchemy COPY
Tiempo Total:                      ~3 minutos
```

### An√°lisis de Claves Primarias
```
√ìrdenes √önicas (order_id):         65,752
Art√≠culos de Orden √önicos (order_item_id):  180,519 ‚úÖ
Clientes √önicos (customer_id):     20,652

An√°lisis de Duplicados:            ‚ùå NINGUNO ENCONTRADO
  - order_item_id: 0 duplicados (tabla limpia)
  - Conclusi√≥n: order_item_id es CLAVE √öNICA viable
```

### Muestra de Datos (5 primeras filas)
```sql
order_id | order_item_id | customer_id | product_name                              | sales      | late_delivery_risk | delivery_status | market
---------|---------------|-------------|-------------------------------------------|------------|--------------------|-----------------|--------
18488    | 46216         | 6395        | Nike Men's CJ Elite 2 TD Football Cleat   | 129.99     | 1                  | Late delivery   | Europe
17589    | 43977         | 7834        | Nike Men's CJ Elite 2 TD Football Cleat   | 129.99     | 1                  | Late delivery   | Europe
71367    | 174682        | 14920       | Porcelain crafts                           | 461.48     | 1                  | Late delivery   | Europe
17589    | 43976         | 7834        | Nike Men's CJ Elite 2 TD Football Cleat   | 129.99     | 1                  | Late delivery   | Europe
62950    | 157418        | 10075       | Nike Men's CJ Elite 2 TD Football Cleat   | 129.99     | 1                  | Late delivery   | Europe
```

---

## üîç VERIFICACIONES COMPLETADAS

‚úÖ **Tabla Creada:** `dw.stg_raw_orders`  
‚úÖ **Filas Cargadas:** 180,519 (100% del CSV)  
‚úÖ **Integridad de Datos:** Validada  
‚úÖ **Duplicados:** 0 encontrados  
‚úÖ **Claves Primarias:** order_item_id es √öNICA  
‚úÖ **Columnas:** 53 (todas normalizadas a snake_case)  
‚úÖ **√çndices:** 3 creados (order_id, order_item_id, customer_id)  
‚úÖ **Encoding:** Caracteres latinos procesados correctamente  

---

## üìã CAMPOS DISPONIBLES EN stg_raw_orders

Nombres normalizados (snake_case):
```
type
days_for_shipping_real
days_for_shipment_scheduled
benefit_per_order
sales_per_customer
delivery_status
late_delivery_risk
category_id
category_name
customer_city
customer_country
customer_email
customer_fname
customer_id
customer_lname
customer_password
customer_segment
customer_state
customer_street
customer_zipcode
department_id
department_name
latitude
longitude
market
order_city
order_country
order_customer_id
order_date_dateorders
order_id
order_item_cardprod_id
order_item_discount
order_item_discount_rate
order_item_id
order_item_product_price
order_item_profit_ratio
order_item_quantity
sales
order_item_total
order_profit_per_order
order_region
order_state
order_status
order_zipcode
product_card_id
product_category_id
product_description
product_image
product_name
product_price
product_status
shipping_date_dateorders
shipping_mode
```

---

## ‚ú® PR√ìXIMOS PASOS - FASE 2.2: TRANSFORMACI√ìN A STAR SCHEMA

### Tarea 2.2.1: Crear Dimensiones
```sql
-- dim_customer: Deduplicar clientes (20,652 √∫nicos de 180K filas)
INSERT INTO dw.dim_customer (customer_id, fname, lname, email, segment, city, state, country)
SELECT DISTINCT 
    customer_id, customer_fname, customer_lname, customer_email, 
    customer_segment, customer_city, customer_state, customer_country
FROM dw.stg_raw_orders;

-- dim_geography: Crear jerarqu√≠a Market ‚Üí Region ‚Üí State ‚Üí City
-- dim_product: Deduplicar productos
-- dim_date: Generar calendario (2015-2026)
```

### Tarea 2.2.2: Transformar a Fact Table
```sql
INSERT INTO dw.fact_orders (...)
SELECT 
    order_item_id,
    customer_id,
    product_id,
    geography_id,
    date_id,
    CAST(sales AS NUMERIC) as sales,
    CAST(benefit_per_order AS NUMERIC) as benefit,
    CAST(order_item_quantity AS INTEGER) as quantity,
    CAST(late_delivery_risk AS INTEGER) as is_late,
    ...
FROM dw.stg_raw_orders;
```

### Tarea 2.2.3: Validar Queries Estrat√©gicas
```sql
-- Q1: OTIF por Market
SELECT * FROM dw.v_otif_by_market;

-- Q2: Revenue at Risk
SELECT * FROM dw.v_revenue_at_risk;

-- Q3: VIP Churn Risk
SELECT * FROM dw.v_churn_risk_vip;

-- Q4: Geographic Efficiency
-- Q5: Fraud/Anomaly Detection
```

---

## üéØ HITOS COMPLETADOS

| Fase | Tarea | Estado | Comentarios |
|------|-------|--------|------------|
| 1.0 | Infraestructura (Docker, PostgreSQL) | ‚úÖ COMPLETADO | Puerto 5433, schema dw creado |
| 2.1 | **Ingesta CSV a Staging** | ‚úÖ **COMPLETADO** | 180,519 filas cargadas, sin duplicados |
| 2.2 | Transformaci√≥n a Star Schema | üìå LISTO PARA INICIAR | SQL queries preparadas en `sql/queries/` |
| 2.3 | Validaci√≥n de Datos | üìå LISTO | Health checks preparados |
| 3.0 | Conexi√≥n Power BI | ‚è≥ PR√ìXIMO | Dashboard 5 vistas |

---

## üõ†Ô∏è COMANDOS DE REFERENCIA

### Verificar Datos
```bash
docker exec supply_chain_db psql -U admin -d supply_chain_dw -c \
  "SELECT COUNT(*) FROM dw.stg_raw_orders;"
```

### Ver Muestra
```bash
docker exec supply_chain_db psql -U admin -d supply_chain_dw -c \
  "SELECT * FROM dw.stg_raw_orders LIMIT 10;"
```

### Estad√≠sticas por Market
```bash
docker exec supply_chain_db psql -U admin -d supply_chain_dw -c \
  "SELECT market, COUNT(*) as count FROM dw.stg_raw_orders GROUP BY market ORDER BY count DESC;"
```

---

## üìù DECISIONES T√âCNICAS DOCUMENTADAS

1. **Tabla Staging con tipos TEXT**: Se cre√≥ `stg_raw_orders` con todos los campos como TEXT para evitar errores de conversi√≥n de tipo durante la carga. Las transformaciones a tipos correctos ocurrir√°n en el paso de Star Schema.

2. **order_item_id como PK**: Se valid√≥ que es 100% √∫nico (180,519 registros sin duplicados), adecuado como clave primaria en fact_orders.

3. **Encoding ISO-8859-1**: Necesario para procesar caracteres latinos en el dataset de DataCo (ciudades, nombres, etc.).

4. **Chunking 50K filas**: Se us√≥ para optimizar memoria durante INSERT (pandas to_sql con chunksize=50000).

---

## ‚úÖ BANDERAZO CONFIRMADO

```
Estado: ‚úÖ LISTO PARA FASE 2.2
CSV:    ‚úÖ 180,519 filas en BD
Schema: ‚úÖ Normalizado (53 columnas)
QA:     ‚úÖ Sin duplicados, sin nulos cr√≠ticos
√çndices: ‚úÖ 3 √≠ndices estrat√©gicos creados

PR√ìXIMO: Ejecutar transformaci√≥n a Star Schema (dim_customer, fact_orders, etc.)
```

---

*Generado por: GitHub Copilot Data Engineering Pipeline*  
*Proyecto: Torre Control - Supply Chain Data Warehouse*  
*Fase: 2.1 Extract & Load (COMPLETADA)*
